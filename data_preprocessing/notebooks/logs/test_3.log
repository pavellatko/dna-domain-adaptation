Namespace(data_name='His.ALL.05.H3K79me1.AllCell.dm6.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', pretrain=None, bottleneck_dim=256, no_pool=False, scratch=True, batch_size=32, lr=0.001, pretrain_lr=0.001, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, pretrain_epochs=10, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='adda-His.ALL.05.H3K79me1.AllCell.dm6.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/adda.py:52: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
0it [00:00, ?it/s]57it [00:00, 532.36it/s]111it [00:00, 511.68it/s]207it [00:00, 656.33it/s]353it [00:00, 892.60it/s]
0it [00:00, ?it/s]14it [00:00, 132.76it/s]105it [00:00, 579.56it/s]255it [00:00, 994.57it/s]353it [00:00, 850.21it/s]
/home/platyshev/.conda/envs/adapt_env/lib/python3.9/site-packages/torch/nn/modules/rnn.py:769: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484806139/work/aten/src/ATen/native/cudnn/RNN.cpp:968.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/22]	Time  3.363 ( 3.363)	Loss 6.0501e-01 (6.0501e-01)	Acc@1  68.75 ( 68.75)
 * Acc@1 63.494
PR AUC 62.002
ROC AUC 66.662
63.49431818181818
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.ce11.hg38', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', arch='hybrid', pretrain=None, bottleneck_dim=256, no_pool=False, scratch=True, batch_size=32, lr=0.001, pretrain_lr=0.001, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, pretrain_epochs=10, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='adda-His.ALL.05.H3K79me1.AllCell.ce11.hg38-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/adda.py:52: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
0it [00:00, ?it/s]194it [00:00, 1937.31it/s]218it [00:00, 2007.66it/s]
0it [00:00, ?it/s]56it [00:00, 522.39it/s]109it [00:00, 407.47it/s]179it [00:00, 455.57it/s]218it [00:00, 478.61it/s]
/home/platyshev/.conda/envs/adapt_env/lib/python3.9/site-packages/torch/nn/modules/rnn.py:769: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484806139/work/aten/src/ATen/native/cudnn/RNN.cpp:968.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/11]	Time  3.096 ( 3.096)	Loss 1.6245e+00 (1.6245e+00)	Acc@1  53.12 ( 53.12)
 * Acc@1 47.443
PR AUC 53.278
ROC AUC 49.990
47.44318181818182
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.hg38.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', no_pool=False, scratch=True, num_blocks=1, bottleneck_dim=256, dropout_p=0.5, batch_size=32, lr=0.001, momentum=0.9, weight_decay=0.0005, trade_off_norm=0.005, trade_off_entropy=None, delta=1, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='afn-His.ALL.05.H3K79me1.AllCell.hg38.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/afn.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/22]	Time  3.009 ( 3.009)	Loss 2.5301e+00 (2.5301e+00)	Acc@1  71.88 ( 71.88)
 * Acc@1 56.676
PR AUC 61.314
ROC AUC 56.082
56.67613636363637
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.hg38.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, randomized=False, randomized_dim=1024, entropy=False, trade_off=0.5, batch_size=32, lr=0.01, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, iters_per_epoch=1000, print_freq=100, seed=1, per_class_eval=False, log='cdan-His.ALL.05.H3K79me1.AllCell.hg38.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/cdan.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/22]	Time  4.309 ( 4.309)	Loss 3.7113e+00 (3.7113e+00)	Acc@1  56.25 ( 56.25)
 * Acc@1 53.125
PR AUC 55.542
ROC AUC 60.980
53.125
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.dm6.mm10', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.mm10.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, trade_off=1.0, batch_size=32, lr=0.01, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='dann-His.ALL.05.H3K79me1.AllCell.dm6.mm10-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/dann.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [  0/777]	Time  4.271 ( 4.271)	Loss 7.6727e-01 (7.6727e-01)	Acc@1  59.38 ( 59.38)
Test: [100/777]	Time  0.004 ( 0.054)	Loss 7.1348e-01 (6.2830e-01)	Acc@1  62.50 ( 67.98)
Test: [200/777]	Time  0.004 ( 0.033)	Loss 5.8500e-01 (6.3376e-01)	Acc@1  62.50 ( 67.21)
Test: [300/777]	Time  0.030 ( 0.026)	Loss 9.7241e-01 (6.3698e-01)	Acc@1  43.75 ( 67.11)
Test: [400/777]	Time  0.004 ( 0.023)	Loss 6.7214e-01 (6.3565e-01)	Acc@1  71.88 ( 67.19)
Test: [500/777]	Time  0.003 ( 0.020)	Loss 8.2366e-01 (6.3705e-01)	Acc@1  53.12 ( 67.11)
Test: [600/777]	Time  0.004 ( 0.018)	Loss 6.2138e-01 (6.3453e-01)	Acc@1  68.75 ( 67.29)
Test: [700/777]	Time  0.007 ( 0.018)	Loss 6.9813e-01 (6.3648e-01)	Acc@1  62.50 ( 67.21)
 * Acc@1 67.342
PR AUC 74.567
ROC AUC 77.923
67.34234234234235
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.dm6.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, trade_off=1.0, batch_size=32, lr=0.01, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='dann-His.ALL.05.H3K79me1.AllCell.dm6.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/dann.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/22]	Time  3.251 ( 3.251)	Loss 1.0325e+00 (1.0325e+00)	Acc@1  53.12 ( 53.12)
 * Acc@1 50.426
PR AUC 56.507
ROC AUC 49.697
50.42613636363637
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.ce11.dm6', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, trade_off=1.0, batch_size=32, lr=0.01, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='dann-His.ALL.05.H3K79me1.AllCell.ce11.dm6-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/dann.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [  0/695]	Time  3.473 ( 3.473)	Loss 2.7216e+00 (2.7216e+00)	Acc@1  43.75 ( 43.75)
Test: [100/695]	Time  0.003 ( 0.048)	Loss 2.7451e+00 (1.8917e+00)	Acc@1  46.88 ( 55.41)
Test: [200/695]	Time  0.019 ( 0.029)	Loss 1.3781e+00 (1.8762e+00)	Acc@1  71.88 ( 55.88)
Test: [300/695]	Time  0.007 ( 0.022)	Loss 1.8326e+00 (1.8892e+00)	Acc@1  46.88 ( 55.49)
Test: [400/695]	Time  0.043 ( 0.019)	Loss 1.7395e+00 (1.8641e+00)	Acc@1  56.25 ( 56.08)
Test: [500/695]	Time  0.004 ( 0.018)	Loss 1.7355e+00 (1.8671e+00)	Acc@1  62.50 ( 56.07)
Test: [600/695]	Time  0.008 ( 0.017)	Loss 1.6727e+00 (1.8808e+00)	Acc@1  59.38 ( 56.06)
 * Acc@1 56.317
PR AUC 59.141
ROC AUC 59.680
56.31744604316547
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.mm10.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.mm10.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', no_pool=False, scratch=True, batch_size=32, lr=0.001, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='src_only-His.ALL.05.H3K79me1.AllCell.mm10.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/erm.py:48: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/22]	Time  4.011 ( 4.011)	Loss 1.5633e+00 (1.5633e+00)	Acc@1  59.38 ( 59.38)
 * Acc@1 54.688
PR AUC 58.857
ROC AUC 46.656
54.6875
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.ce11.dm6', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', arch='hybrid', no_pool=False, scratch=True, batch_size=32, lr=0.001, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='src_only-His.ALL.05.H3K79me1.AllCell.ce11.dm6-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/erm.py:48: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [  0/695]	Time  3.135 ( 3.135)	Loss 2.5355e+00 (2.5355e+00)	Acc@1  46.88 ( 46.88)
Test: [100/695]	Time  0.047 ( 0.040)	Loss 1.9179e+00 (1.9777e+00)	Acc@1  59.38 ( 57.92)
Test: [200/695]	Time  0.006 ( 0.026)	Loss 2.0730e+00 (1.9643e+00)	Acc@1  65.62 ( 58.02)
Test: [300/695]	Time  0.005 ( 0.021)	Loss 2.1715e+00 (2.0005e+00)	Acc@1  53.12 ( 57.54)
Test: [400/695]	Time  0.006 ( 0.018)	Loss 2.4060e+00 (2.0061e+00)	Acc@1  59.38 ( 57.79)
Test: [500/695]	Time  0.051 ( 0.017)	Loss 1.2698e+00 (1.9976e+00)	Acc@1  75.00 ( 57.93)
Test: [600/695]	Time  0.005 ( 0.016)	Loss 1.6788e+00 (1.9991e+00)	Acc@1  65.62 ( 57.84)
 * Acc@1 57.828
PR AUC 59.258
ROC AUC 61.808
57.82823741007194
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.dm6.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, linear=False, adversarial=False, trade_off=0.5, batch_size=32, lr=0.003, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='jan-His.ALL.05.H3K79me1.AllCell.dm6.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/jan.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/22]	Time  3.476 ( 3.476)	Loss 1.6830e+00 (1.6830e+00)	Acc@1  43.75 ( 43.75)
 * Acc@1 48.011
PR AUC 51.013
ROC AUC 44.030
48.01136363636363
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.ce11.hg38', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, linear=False, adversarial=False, trade_off=0.5, batch_size=32, lr=0.003, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='jan-His.ALL.05.H3K79me1.AllCell.ce11.hg38-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/jan.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/11]	Time  3.202 ( 3.202)	Loss 6.3876e+00 (6.3876e+00)	Acc@1  40.62 ( 40.62)
 * Acc@1 49.716
PR AUC 54.156
ROC AUC 49.025
49.71590909090909
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.hg38.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, temperature=2.5, trade_off=0.05, batch_size=36, lr=0.005, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='mcc-His.ALL.05.H3K79me1.AllCell.hg38.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcc.py:39: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/19]	Time  2.274 ( 2.274)	Loss 4.4641e+00 (4.4641e+00)	Acc@1  63.89 ( 63.89)
 * Acc@1 47.953
PR AUC 50.376
ROC AUC 42.016
47.95321454499897
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.hg38.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, trade_off=0.1, trade_off_entropy=0.01, num_k=4, batch_size=32, lr=0.001, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='mcd-His.ALL.05.H3K79me1.AllCell.hg38.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcd.py:43: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcd.py:284: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y1_preds.append(F.softmax(y1))
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcd.py:285: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y2_preds.append(F.softmax(y2))
Test: [ 0/22]	Time  2.195 ( 2.195)	Acc_1  43.75 ( 43.75)	Acc_2  43.75 ( 43.75)
 * Acc1 50.426 Acc2 50.568
F1 PR AUC 55.938
F2 PR AUC 56.017
F1 ROC AUC 44.054
F2 ROC AUC 44.132
(50.42613636363637, 50.56818181818182)
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.hg38.dm6', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, margin=4.0, trade_off=0.5, batch_size=32, lr=0.004, lr_gamma=0.0002, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='mdd-His.ALL.05.H3K79me1.AllCell.hg38.dm6-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mdd.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [  0/695]	Time  2.416 ( 2.416)	Loss 1.6699e+00 (1.6699e+00)	Acc@1  65.62 ( 65.62)
Test: [100/695]	Time  0.004 ( 0.032)	Loss 1.9233e+00 (2.4424e+00)	Acc@1  68.75 ( 62.35)
Test: [200/695]	Time  0.003 ( 0.020)	Loss 2.0746e+00 (2.3884e+00)	Acc@1  71.88 ( 62.39)
Test: [300/695]	Time  0.004 ( 0.015)	Loss 2.4180e+00 (2.3849e+00)	Acc@1  53.12 ( 62.08)
Test: [400/695]	Time  0.039 ( 0.013)	Loss 2.5479e+00 (2.3704e+00)	Acc@1  62.50 ( 62.13)
Test: [500/695]	Time  0.003 ( 0.012)	Loss 2.1686e+00 (2.3835e+00)	Acc@1  68.75 ( 62.04)
Test: [600/695]	Time  0.004 ( 0.011)	Loss 1.4515e+00 (2.3928e+00)	Acc@1  68.75 ( 62.00)
 * Acc@1 62.131
PR AUC 64.817
ROC AUC 66.202
62.131294964028775
