Namespace(data_name='His.ALL.05.H3K79me1.AllCell.hg38.dm6', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', arch='hybrid', pretrain=None, bottleneck_dim=256, no_pool=False, scratch=True, batch_size=32, lr=0.001, pretrain_lr=0.001, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, pretrain_epochs=10, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='adda-His.ALL.05.H3K79me1.AllCell.hg38.dm6-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/adda.py:52: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
0it [00:00, ?it/s]80it [00:00, 718.72it/s]230it [00:00, 1112.53it/s]342it [00:00, 857.74it/s] 501it [00:00, 1094.45it/s]619it [00:00, 641.41it/s] 766it [00:00, 800.03it/s]871it [00:01, 820.12it/s]971it [00:01, 643.57it/s]1088it [00:01, 659.76it/s]1166it [00:01, 669.49it/s]1417it [00:01, 1073.36it/s]1659it [00:01, 1340.36it/s]1812it [00:01, 1161.28it/s]1945it [00:02, 888.73it/s] 2194it [00:02, 1199.62it/s]2345it [00:02, 1103.90it/s]2478it [00:02, 845.62it/s] 2586it [00:02, 861.15it/s]2689it [00:02, 887.96it/s]2846it [00:03, 997.35it/s]2957it [00:03, 808.43it/s]3061it [00:03, 833.99it/s]3154it [00:03, 709.78it/s]3234it [00:03, 658.43it/s]3382it [00:03, 833.23it/s]3489it [00:03, 887.78it/s]3598it [00:04, 885.33it/s]3693it [00:04, 774.40it/s]3781it [00:04, 758.44it/s]3868it [00:04, 785.37it/s]3982it [00:04, 876.12it/s]4074it [00:04, 887.37it/s]4166it [00:04, 894.37it/s]4297it [00:04, 957.97it/s]4394it [00:05, 940.32it/s]4489it [00:05, 892.52it/s]4580it [00:05, 717.70it/s]4658it [00:05, 681.30it/s]4820it [00:05, 874.15it/s]4925it [00:05, 885.05it/s]5029it [00:05, 913.41it/s]5129it [00:05, 931.28it/s]5242it [00:06, 964.35it/s]5409it [00:06, 1159.27it/s]5528it [00:06, 912.18it/s] 5630it [00:06, 842.29it/s]5748it [00:06, 921.03it/s]5896it [00:06, 1037.89it/s]6007it [00:06, 943.00it/s] 6107it [00:07, 709.10it/s]6211it [00:07, 751.14it/s]6296it [00:07, 643.23it/s]6455it [00:07, 769.51it/s]6565it [00:07, 839.97it/s]6657it [00:07, 786.60it/s]6909it [00:07, 1193.10it/s]7044it [00:08, 915.54it/s] 7155it [00:08, 916.15it/s]7261it [00:08, 911.82it/s]7362it [00:08, 932.76it/s]7463it [00:08, 871.26it/s]7556it [00:08, 828.45it/s]7643it [00:08, 791.90it/s]7725it [00:08, 788.64it/s]7859it [00:09, 915.05it/s]7953it [00:09, 815.63it/s]8038it [00:09, 716.52it/s]8123it [00:09, 745.74it/s]8373it [00:09, 1178.58it/s]8500it [00:09, 993.16it/s] 8610it [00:09, 999.50it/s]8718it [00:09, 936.77it/s]8818it [00:10, 951.88it/s]9000it [00:10, 1178.12it/s]9125it [00:10, 961.94it/s] 9232it [00:10, 798.06it/s]9374it [00:10, 871.21it/s]9470it [00:10, 831.47it/s]9585it [00:10, 903.90it/s]9812it [00:11, 1240.59it/s]9948it [00:11, 850.73it/s] 10058it [00:11, 832.82it/s]10309it [00:11, 1181.61it/s]10467it [00:11, 1131.49it/s]10600it [00:11, 902.27it/s] 10710it [00:12, 914.84it/s]10856it [00:12, 1032.10it/s]10974it [00:12, 996.97it/s] 11084it [00:12, 948.01it/s]11139it [00:12, 893.16it/s]
0it [00:00, ?it/s]153it [00:00, 1397.51it/s]293it [00:00, 1090.08it/s]406it [00:00, 1012.43it/s]510it [00:00, 881.27it/s] 601it [00:00, 674.06it/s]730it [00:00, 761.03it/s]831it [00:01, 768.82it/s]942it [00:01, 851.56it/s]1083it [00:01, 995.19it/s]1189it [00:01, 987.54it/s]1293it [00:01, 875.44it/s]1390it [00:01, 898.92it/s]1578it [00:01, 1136.06it/s]1697it [00:02, 644.66it/s] 1807it [00:02, 676.52it/s]1919it [00:02, 732.54it/s]2113it [00:02, 984.42it/s]2311it [00:02, 1211.99it/s]2455it [00:02, 1033.02it/s]2579it [00:02, 869.02it/s] 2683it [00:03, 853.94it/s]2797it [00:03, 915.35it/s]2900it [00:03, 889.27it/s]3097it [00:03, 916.52it/s]3193it [00:03, 898.96it/s]3286it [00:03, 786.82it/s]3458it [00:03, 993.94it/s]3711it [00:03, 1363.53it/s]3920it [00:04, 1397.93it/s]4071it [00:04, 1289.62it/s]4209it [00:04, 916.20it/s] 4352it [00:04, 995.82it/s]4469it [00:04, 1030.47it/s]4586it [00:04, 874.96it/s] 4686it [00:05, 817.42it/s]4801it [00:05, 872.84it/s]4919it [00:05, 905.09it/s]5016it [00:05, 892.93it/s]5126it [00:05, 904.47it/s]5265it [00:05, 939.24it/s]5361it [00:05, 827.00it/s]5447it [00:05, 794.97it/s]5677it [00:06, 1068.67it/s]5785it [00:06, 1012.53it/s]5887it [00:06, 700.19it/s] 6091it [00:06, 863.63it/s]6187it [00:06, 845.35it/s]6278it [00:06, 775.23it/s]6411it [00:07, 858.59it/s]6563it [00:07, 892.28it/s]6656it [00:07, 692.14it/s]6783it [00:07, 805.88it/s]6929it [00:07, 949.41it/s]7179it [00:07, 1319.63it/s]7330it [00:07, 1144.22it/s]7465it [00:08, 1076.29it/s]7585it [00:08, 1040.32it/s]7697it [00:08, 875.54it/s] 7794it [00:08, 881.34it/s]8047it [00:08, 1268.65it/s]8189it [00:08, 770.95it/s] 8375it [00:09, 960.92it/s]8509it [00:09, 955.08it/s]8631it [00:09, 949.40it/s]8744it [00:09, 975.84it/s]8855it [00:09, 938.66it/s]8959it [00:09, 838.37it/s]9131it [00:09, 950.48it/s]9279it [00:09, 1030.10it/s]9388it [00:10, 962.67it/s] 9488it [00:10, 816.15it/s]9634it [00:10, 932.63it/s]9734it [00:10, 833.28it/s]9836it [00:10, 802.23it/s]10087it [00:10, 1195.17it/s]10221it [00:10, 1067.12it/s]10340it [00:11, 879.18it/s] 10457it [00:11, 917.02it/s]10633it [00:11, 1108.89it/s]10757it [00:11, 927.22it/s] 10863it [00:11, 859.07it/s]10989it [00:11, 872.33it/s]11083it [00:12, 826.43it/s]11139it [00:12, 919.73it/s]
/home/platyshev/.conda/envs/adapt_env/lib/python3.9/site-packages/torch/nn/modules/rnn.py:769: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484806139/work/aten/src/ATen/native/cudnn/RNN.cpp:968.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [  0/695]	Time  3.091 ( 3.091)	Loss 3.4913e+00 (3.4913e+00)	Acc@1  59.38 ( 59.38)
Test: [100/695]	Time  0.005 ( 0.044)	Loss 2.6222e+00 (2.6996e+00)	Acc@1  68.75 ( 62.10)
Test: [200/695]	Time  0.055 ( 0.028)	Loss 3.3947e+00 (2.6472e+00)	Acc@1  59.38 ( 62.30)
Test: [300/695]	Time  0.003 ( 0.023)	Loss 2.1934e+00 (2.6608e+00)	Acc@1  71.88 ( 62.14)
Test: [400/695]	Time  0.005 ( 0.021)	Loss 3.0475e+00 (2.6685e+00)	Acc@1  62.50 ( 62.16)
Test: [500/695]	Time  0.011 ( 0.019)	Loss 2.2451e+00 (2.6727e+00)	Acc@1  68.75 ( 62.09)
Test: [600/695]	Time  0.004 ( 0.018)	Loss 2.6819e+00 (2.6659e+00)	Acc@1  46.88 ( 62.27)
 * Acc@1 62.253
PR AUC 64.639
ROC AUC 67.116
62.25269784172662
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.mm10.hg38', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.mm10.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', arch='hybrid', no_pool=False, scratch=True, num_blocks=1, bottleneck_dim=256, dropout_p=0.5, batch_size=32, lr=0.001, momentum=0.9, weight_decay=0.0005, trade_off_norm=0.005, trade_off_entropy=None, delta=1, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='afn-His.ALL.05.H3K79me1.AllCell.mm10.hg38-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/afn.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/11]	Time  3.459 ( 3.459)	Loss 1.1603e+00 (1.1603e+00)	Acc@1  59.38 ( 59.38)
 * Acc@1 55.966
PR AUC 54.956
ROC AUC 52.150
55.96590909090909
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.dm6.hg38', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, randomized=False, randomized_dim=1024, entropy=False, trade_off=0.5, batch_size=32, lr=0.01, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, iters_per_epoch=1000, print_freq=100, seed=1, per_class_eval=False, log='cdan-His.ALL.05.H3K79me1.AllCell.dm6.hg38-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/cdan.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/11]	Time  3.786 ( 3.786)	Loss 1.4958e+00 (1.4958e+00)	Acc@1  46.88 ( 46.88)
 * Acc@1 48.580
PR AUC 58.053
ROC AUC 47.690
48.57954545454545
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.ce11.mm10', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.mm10.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, randomized=False, randomized_dim=1024, entropy=False, trade_off=0.5, batch_size=32, lr=0.01, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, iters_per_epoch=1000, print_freq=100, seed=1, per_class_eval=False, log='cdan-His.ALL.05.H3K79me1.AllCell.ce11.mm10-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/cdan.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [  0/777]	Time  3.118 ( 3.118)	Loss 2.2250e+00 (2.2250e+00)	Acc@1  71.88 ( 71.88)
Test: [100/777]	Time  0.004 ( 0.042)	Loss 2.8035e+00 (2.6717e+00)	Acc@1  68.75 ( 68.60)
Test: [200/777]	Time  0.006 ( 0.027)	Loss 2.5235e+00 (2.6274e+00)	Acc@1  68.75 ( 68.92)
Test: [300/777]	Time  0.003 ( 0.021)	Loss 2.9324e+00 (2.6619e+00)	Acc@1  65.62 ( 68.57)
Test: [400/777]	Time  0.004 ( 0.018)	Loss 3.4318e+00 (2.6831e+00)	Acc@1  68.75 ( 68.24)
Test: [500/777]	Time  0.004 ( 0.016)	Loss 1.6092e+00 (2.6472e+00)	Acc@1  75.00 ( 68.38)
Test: [600/777]	Time  0.006 ( 0.015)	Loss 1.8143e+00 (2.6271e+00)	Acc@1  75.00 ( 68.57)
Test: [700/777]	Time  0.003 ( 0.015)	Loss 2.7571e+00 (2.6320e+00)	Acc@1  68.75 ( 68.43)
 * Acc@1 68.444
PR AUC 79.944
ROC AUC 78.894
68.4443371943372
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.hg38.dm6', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, non_linear=False, trade_off=0.5, batch_size=32, lr=0.003, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='dan-His.ALL.05.H3K79me1.AllCell.hg38.dm6-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/dan.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [  0/695]	Time  3.037 ( 3.037)	Loss 3.4139e+00 (3.4139e+00)	Acc@1  53.12 ( 53.12)
Test: [100/695]	Time  0.013 ( 0.039)	Loss 3.4470e+00 (3.1510e+00)	Acc@1  53.12 ( 60.58)
Test: [200/695]	Time  0.004 ( 0.025)	Loss 2.2699e+00 (3.1149e+00)	Acc@1  65.62 ( 61.19)
Test: [300/695]	Time  0.003 ( 0.020)	Loss 3.0986e+00 (3.1120e+00)	Acc@1  59.38 ( 61.03)
Test: [400/695]	Time  0.019 ( 0.017)	Loss 3.7620e+00 (3.1065e+00)	Acc@1  56.25 ( 61.35)
Test: [500/695]	Time  0.004 ( 0.015)	Loss 1.3994e+00 (3.0992e+00)	Acc@1  75.00 ( 61.35)
Test: [600/695]	Time  0.004 ( 0.014)	Loss 5.2359e+00 (3.1267e+00)	Acc@1  43.75 ( 61.26)
 * Acc@1 61.457
PR AUC 65.206
ROC AUC 67.608
61.4568345323741
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.mm10.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.mm10.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, trade_off=1.0, batch_size=32, lr=0.01, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='dann-His.ALL.05.H3K79me1.AllCell.mm10.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/dann.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/22]	Time  3.557 ( 3.557)	Loss 1.5298e+00 (1.5298e+00)	Acc@1  62.50 ( 62.50)
 * Acc@1 46.875
PR AUC 55.719
ROC AUC 45.272
46.875
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.dm6.mm10', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.mm10.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random.fa', arch='hybrid', no_pool=False, scratch=True, batch_size=32, lr=0.001, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='src_only-His.ALL.05.H3K79me1.AllCell.dm6.mm10-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/erm.py:48: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [  0/777]	Time  3.432 ( 3.432)	Loss 4.8574e-01 (4.8574e-01)	Acc@1  81.25 ( 81.25)
Test: [100/777]	Time  0.003 ( 0.045)	Loss 5.1132e-01 (5.2179e-01)	Acc@1  75.00 ( 73.98)
Test: [200/777]	Time  0.005 ( 0.029)	Loss 3.7803e-01 (5.1295e-01)	Acc@1  87.50 ( 74.97)
Test: [300/777]	Time  0.003 ( 0.022)	Loss 4.0133e-01 (5.1241e-01)	Acc@1  87.50 ( 75.36)
Test: [400/777]	Time  0.058 ( 0.020)	Loss 5.3221e-01 (5.1319e-01)	Acc@1  75.00 ( 75.35)
Test: [500/777]	Time  0.008 ( 0.018)	Loss 4.6775e-01 (5.1286e-01)	Acc@1  90.62 ( 75.48)
Test: [600/777]	Time  0.003 ( 0.017)	Loss 5.2043e-01 (5.1268e-01)	Acc@1  78.12 ( 75.52)
Test: [700/777]	Time  0.003 ( 0.016)	Loss 5.6362e-01 (5.1086e-01)	Acc@1  68.75 ( 75.74)
 * Acc@1 75.684
PR AUC 84.573
ROC AUC 84.069
75.68371943371943
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.dm6.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', no_pool=False, scratch=True, batch_size=32, lr=0.001, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='src_only-His.ALL.05.H3K79me1.AllCell.dm6.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/erm.py:48: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/22]	Time  3.831 ( 3.831)	Loss 7.4679e-01 (7.4679e-01)	Acc@1  62.50 ( 62.50)
 * Acc@1 60.938
PR AUC 65.223
ROC AUC 59.565
60.9375
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.mm10.hg38', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.mm10.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', arch='hybrid', no_pool=False, scratch=True, batch_size=32, lr=0.001, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='src_only-His.ALL.05.H3K79me1.AllCell.mm10.hg38-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/erm.py:48: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/11]	Time  3.702 ( 3.702)	Loss 1.7033e+00 (1.7033e+00)	Acc@1  59.38 ( 59.38)
 * Acc@1 61.080
PR AUC 63.960
ROC AUC 62.240
61.07954545454545
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.hg38.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', no_pool=False, scratch=True, batch_size=32, lr=0.001, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='src_only-His.ALL.05.H3K79me1.AllCell.hg38.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/erm.py:48: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/22]	Time  2.914 ( 2.914)	Loss 2.1171e+00 (2.1171e+00)	Acc@1  50.00 ( 50.00)
 * Acc@1 59.801
PR AUC 62.410
ROC AUC 55.869
59.80113636363637
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.hg38.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, linear=False, adversarial=False, trade_off=0.5, batch_size=32, lr=0.003, lr_gamma=0.0003, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='jan-His.ALL.05.H3K79me1.AllCell.hg38.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/jan.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/22]	Time  3.400 ( 3.400)	Loss 3.8539e+00 (3.8539e+00)	Acc@1  59.38 ( 59.38)
 * Acc@1 46.449
PR AUC 50.905
ROC AUC 46.630
46.44886363636363
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.ce11.mm10', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.mm10.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.mm10.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, temperature=2.5, trade_off=0.05, batch_size=36, lr=0.005, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='mcc-His.ALL.05.H3K79me1.AllCell.ce11.mm10-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcc.py:39: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [  0/690]	Time  3.073 ( 3.073)	Loss 5.5026e+00 (5.5026e+00)	Acc@1  58.33 ( 58.33)
Test: [100/690]	Time  0.005 ( 0.041)	Loss 2.1274e+00 (3.0745e+00)	Acc@1  77.78 ( 71.15)
Test: [200/690]	Time  0.006 ( 0.025)	Loss 2.7396e+00 (3.1822e+00)	Acc@1  66.67 ( 70.25)
Test: [300/690]	Time  0.004 ( 0.020)	Loss 3.2726e+00 (3.1457e+00)	Acc@1  63.89 ( 70.29)
Test: [400/690]	Time  0.005 ( 0.017)	Loss 3.4401e+00 (3.1838e+00)	Acc@1  61.11 ( 69.93)
Test: [500/690]	Time  0.003 ( 0.016)	Loss 2.1748e+00 (3.1942e+00)	Acc@1  80.56 ( 69.94)
Test: [600/690]	Time  0.005 ( 0.015)	Loss 3.2203e+00 (3.2460e+00)	Acc@1  72.22 ( 69.51)
 * Acc@1 69.432
PR AUC 80.009
ROC AUC 79.269
69.43236440022787
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.dm6.ce11', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.dm6.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.dm6.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, trade_off=0.1, trade_off_entropy=0.01, num_k=4, batch_size=32, lr=0.001, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='mcd-His.ALL.05.H3K79me1.AllCell.dm6.ce11-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcd.py:43: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcd.py:284: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y1_preds.append(F.softmax(y1))
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcd.py:285: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y2_preds.append(F.softmax(y2))
Test: [ 0/22]	Time  2.377 ( 2.377)	Acc_1  53.12 ( 53.12)	Acc_2  53.12 ( 53.12)
 * Acc1 56.250 Acc2 57.386
F1 PR AUC 73.088
F2 PR AUC 73.150
F1 ROC AUC 72.658
F2 ROC AUC 72.734
(56.25, 57.38636363636363)
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.ce11.hg38', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, trade_off=0.1, trade_off_entropy=0.01, num_k=4, batch_size=32, lr=0.001, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='mcd-His.ALL.05.H3K79me1.AllCell.ce11.hg38-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcd.py:43: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcd.py:284: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y1_preds.append(F.softmax(y1))
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mcd.py:285: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y2_preds.append(F.softmax(y2))
Test: [ 0/11]	Time  3.689 ( 3.689)	Acc_1  43.75 ( 43.75)	Acc_2  43.75 ( 43.75)
 * Acc1 52.841 Acc2 52.841
F1 PR AUC 57.227
F2 PR AUC 57.290
F1 ROC AUC 51.395
F2 ROC AUC 51.335
(52.84090909090909, 52.84090909090909)
Namespace(data_name='His.ALL.05.H3K79me1.AllCell.ce11.hg38', ds_cache='datasets', source_positive='His.ALL.05.H3K79me1.AllCell.ce11.preproc.fa', source_negative='His.ALL.05.H3K79me1.AllCell.ce11.preproc.random.fa', target_train='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random2x.fa', target_positive='His.ALL.05.H3K79me1.AllCell.hg38.preproc.fa', target_negative='His.ALL.05.H3K79me1.AllCell.hg38.preproc.random.fa', arch='hybrid', bottleneck_dim=256, no_pool=False, scratch=True, margin=4.0, trade_off=0.5, batch_size=32, lr=0.004, lr_gamma=0.0002, lr_decay=0.75, momentum=0.9, wd=0.0005, workers=2, epochs=120, iters_per_epoch=500, print_freq=100, seed=1, per_class_eval=False, log='mdd-His.ALL.05.H3K79me1.AllCell.ce11.hg38-seed-1', phase='test')
/home/platyshev/His.ALL.05.H3K79me1.AllCell/../methods/mdd.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using model 'hybrid'
/home/platyshev/Sequence-Transfer-Learning-Library/examples/domain_adaptation/dna_classification/utils.py:194: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  y_preds.append(F.softmax(output))
Test: [ 0/11]	Time  1.835 ( 1.835)	Loss 2.4215e+00 (2.4215e+00)	Acc@1  56.25 ( 56.25)
 * Acc@1 52.841
PR AUC 57.772
ROC AUC 54.612
52.84090909090909
